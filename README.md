# Assignment_3
Course: Collecting Data | Student Number: S6494935

1. Your github repository should contain:
    1.1. A single CSV file with a column that contains the data (e.g., article, poem, image) and subsequent column(s) for metadata.
    1.2. The code (Jupyter Notebook) you used to scrape the web page and clean the text.
    1.3. A README.md file with the relevant documentation, including the information on the terms and conditions for web scraping.
        User-agent: Twitterbot
        Disallow:

        User-agent: *
        Disallow: /scrapperlayout
        Disallow: */page/*?loadmore=*
        Disallow: /data-api

3. Documentation should include a brief description of: 
    2.1. Corpus itself.
    2.2. The data you have scraped.
    2.3. Cleaning steps if youâ€™ve done any.
    2.4. Format of the files in the corpus (in this case, csv).
    2.5. Mention of the terms and conditions under which you can access and use the data you scraped.
    2.6. Your Jupyter Notebook should contain all the code used for scraping and cleaning the text. The Jupyter Notebook should end with saving your corpus as a CSV file.
    2.7. Submit a link to your github repository. 